[
["index.html", "MARSS wiki 1 Contribute", " MARSS wiki EE Holmes 2018-03-15 1 Contribute Write an Rmd file. Add via a pull-request. Each Rmd file contains one and only one entry/vignette. The title of your vignette must be at the top of your Rmd and have # (chapter level). Subsequent headings should be ##. "],
["plot-states-from-a-dfa-using-ggplot.html", "2 Plot states from a DFA using ggplot", " 2 Plot states from a DFA using ggplot author: EE Holmes date: March 15, 2018 Requires MARSS 3.10.4+ Required packages library(MARSS) library(broom) library(ggplot2) Load data and zscore data(lakeWAplankton) # we want lakeWAplanktonTrans, which has been log-transformed # and the 0s replaced with NAs plankdat = lakeWAplanktonTrans years = plankdat[,&quot;Year&quot;]&gt;=1980 &amp; plankdat[,&quot;Year&quot;]&lt;1990 phytos = c(&quot;Cryptomonas&quot;, &quot;Diatoms&quot;, &quot;Greens&quot;, &quot;Unicells&quot;, &quot;Other.algae&quot;) dat.spp.1980 = plankdat[years,phytos] # transpose data so time goes across columns dat.spp.1980 = t(dat.spp.1980) dat.z = zscore(dat.spp.1980) Fit a DFA with 3 trends. Setting maxit to 50, so it runs fast. model.list = list(m=3, R=&quot;diagonal and unequal&quot;) kemz.3 = MARSS(dat.spp.1980, model=model.list, z.score=TRUE, form=&quot;dfa&quot;, control=list(maxit=50)) Make a plot of trends with CIs theme_set(theme_bw()) d &lt;- tidy(kemz.3, type=&quot;states&quot;) ggplot(data = d) + geom_line(aes(t, estimate)) + geom_ribbon(aes(x=t, ymin=conf.low, ymax=conf.high), linetype=2, alpha=0.1) + facet_grid(~term) + xlab(&quot;Time Step&quot;) + ylab(&quot;Val&quot;) "],
["test-math.html", "3 test math 3.1 Univariate linear regression", " 3 test math author: EE Holmes date: March 15, 2018 This chapter shows how to write regression models with multivariate responses and multivariate explanatory variables in MARSS form. R has many excellent packages for multiple linear regression. We will be showing how to use the MARSS() function to fit these models, but note that Râ€™s standard linear regression functions would be much better choices in most cases. The purpose of this chapter is to show the relationship between multivariate linear regression and the MARSS equation. In a classic linear regression, the response variable (\\(y\\)) is univariate and there may one to multiple explanatory variables (\\(d_1\\), \\(d_2\\), \\(\\dots\\)) plus an optional intercept (\\(\\alpha\\)): \\[\\begin{equation}\\label{eqn:lm} y_t = \\alpha + \\sum_k\\beta_k d_k + e_t, \\text{ where } e_t \\sim \\N(0,\\sigma^2) \\end{equation}\\] Here the subscript, \\(t\\) is used since we are working with time-series data. Explanatory variables are normally denoted \\(x\\) in linear regression however \\(x\\) is not used here since \\(x\\) is already used in MARSS models to denote the hidden process trajectory. Instead \\(d\\) is used when the explanatory variables appear in the \\(y\\) part of the equation (and \\(c\\) if they appear in the \\(x\\) part). This chapter will start with classical linear regression where the explanatory variables are treated as inputs that are known without error and where we are trying to explain the variation in \\(y\\) with our explanatory variables. We will extend this to the case of autocorrelated errors. 3.1 Univariate linear regression A vanilla linear regression where our data are time ordered but we treat them as independent can be written \\[\\begin{equation}\\label{eqn:lm2} y_t=\\alpha + \\beta_1 d_{1,t} + \\beta_2 d_{2,t} + e_t, \\end{equation}\\] "]
]
